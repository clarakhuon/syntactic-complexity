---
title: "Task Y - Bivariate Correlations (Text-Length Boundary)"
author: "Clara Khuon"
date: "January 15th, 2026"
output: html_document
---

## Correlations for Task Y with PHQ Scores at Timepoint 5 ##

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set working directory
setwd("...")

# Load libraries
library(tidyverse)
library(here)
library(caret)
library(lattice)
library(parallel)
library(doParallel)
library(foreach)
library(glmnet)
library(Hmisc)
library(randomForest)
library(lsr)
library(car)
library(ggplot2)
library(corrplot)

# Load data
demographic_data <- read_csv(file = here("demographic_data.csv"))
taskY_TAASSC <- read_csv(file = here("taskY_linguistic_data_TAASSC.csv"))
taskY_SCA <- read_csv(file = here("taskY_linguistic_data_SCA.csv"))

# Note: File names above are example placeholders

```

# Preprocessing 1
```{r}
# Filter demographic dataset to specific variables
taskY_demographic_variables <- c("UserID_v2", "T5_PHQ9_Total", "Age", "Gender", "Education", "Diagnosis_Onset", "TaskY_1_Acceptability1", "TaskY_1_Acceptability2", "TaskY_1_Acceptability3")
taskY_demographic_data <- demographic_data[, taskY_demographic_variables]

# Order SCA dataset in ascending order of participant ID number
taskY_SCA$filename <- basename(taskY_TAASSC$filename)
taskY_SCA$filename <- str_remove(taskY_SCA$filename,".txt")
taskY_SCA$filename <- str_remove(taskY_SCA$filename,"TaskY.Participant")
taskY_SCA <- taskY_SCA[order(as.numeric(taskY_SCA$filename), decreasing = FALSE), ]
taskY_SCA$filename <- paste("Participant.", taskY_SCA$filename, sep = "")

# Order TAASSC dataset in ascending order of participant ID number
taskY_TAASSC$filename <- str_remove(taskY_TAASSC$filename,".txt")
taskY_TAASSC$filename <- str_remove(taskY_TAASSC$filename,"TaskY.Participant")
taskY_TAASSC <- taskY_TAASSC[order(as.numeric(taskY_TAASSC$filename), decreasing = FALSE), ]
taskY_TAASSC$filename <- paste("Participant.", taskY_TAASSC$filename, sep = "")

# Remove predictor variables with near-zero variance from TAASSC dataset
near_zero_table <- nearZeroVar(taskY_TAASSC, saveMetrics = TRUE)
near_zero_TAASSC <- nearZeroVar(taskY_TAASSC) 
taskY_TAASSC <- taskY_TAASSC[,-near_zero_TAASSC]

# Combine demographic dataset with TAASCC and SCA datasets (without duplicate participant ID number and word-count columns)
taskY_total <- cbind(taskY_demographic_data, taskY_TAASSC, taskY_SCA[,3:16])

# Identify and remove participants with invalid writing samples (i.e., word-count of zero)
invalid <- filter(taskY_total, nwords == 0)
taskY_filtered <- filter(taskY_total, nwords != 0)

# Remove second ID column
taskY_filtered <- taskY_filtered[,-which(colnames(taskY_filtered) == "filename")]

# Define gender and education as categorical variables in final dataset
taskY_filtered$Gender <- as.factor(taskY_filtered$Gender)
taskY_filtered$Education <- as.factor(taskY_filtered$Education)

# Final dataset
taskY_final <- taskY_filtered
taskY_final 

```

# Preprocessing 2
Identify and remove highly-correlated predictor variables
```{r}
# Isolate dataset columns with predictor variables
taskY_variables <- taskY_final[,which(colnames(taskY_final)=="nwords"):dim(taskY_final)[2]] 

# Create correlation matrix of predictor variables
cor_matrix <- cor(taskY_variables, use = "complete.obs")

# Identify highly correlated variables
highly_correlated <- findCorrelation(cor_matrix, cutoff = 0.75)

# Add number of columns to vector of column names to align with length of original filtered dataset
highly_correlated <- highly_correlated + length(taskY_demographic_variables)

# Remove highly correlated variables from original filtered dataset
taskY_final <- taskY_final[,-highly_correlated]

# Final dataset
taskY_final

```

# Impose Text-Length Boundary from 100-200 Words
```{r}
# Refine to participants with text samples of between 100-200 words
taskY_final <- filter(taskY_final, nwords >= 100 & nwords <= 200)

# Refined dataset
taskY_final
taskY_final_df <- as.data.frame(taskY_final) # 67 participants 

```

## Run Select Bivariate Correlations with Text-Length Boundary
Re-run bivariate correlations that had originally been significant, imposing text-length boundary
```{r}

taskY_cor5 <- cor.test(taskY_final_df$T5_PHQ9_Total, taskY_final_df$news_av_lemma_construction_freq_type) 
taskY_cor6 <- cor.test(taskY_final_df$T5_PHQ9_Total, taskY_final_df$news_av_lemma_construction_freq_log_stdev) 

```

# Create Results Dataframe
With FDR-corrected p-values
```{r}

# create empty 2 x 3 matrix; convert matrix to dataframe; rename column names
taskY_results <- matrix(NA, nrow = 2, ncol = 3)
taskY_results <- data.frame(taskY_results) 
colnames(taskY_results) <- c("variable", "r", "p_value_adjusted")       

# fill dataframe with values from correlation results
taskY_results[1,1] <- "news_av_lemma_construction_freq_type"    
taskY_results[1,2] <- taskY_cor5$estimate         
taskY_results[1,3] <- p.adjust(taskY_cor5$p.value, method = "fdr")          

taskY_results[2,1] <- "news_av_lemma_construction_freq_log_stdev"    
taskY_results[2,2] <- taskY_cor6$estimate         
taskY_results[2,3] <- p.adjust(taskY_cor6$p.value, method = "fdr")

taskY_results

```
