---
title: "Task V - Bivariate Correlations"
author: "Clara Khuon"
date: "January 15th, 2026"
output: html_document
---

## Correlations for Task V with PHQ Scores at Timepoint 2 ##

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set working directory
setwd("...")

# Load libraries
library(tidyverse)
library(here)
library(caret)
library(lattice)
library(parallel)
library(doParallel)
library(foreach)
library(glmnet)
library(Hmisc)
library(randomForest)
library(lsr)
library(car)
library(ggplot2)
library(corrplot)

# Load data
demographic_data <- read_csv(file = here("demographic_data.csv"))
taskV_TAASSC <- read_csv(file = here("taskV_linguistic_data_TAASSC.csv"))
taskV_SCA <- read_csv(file = here("taskV_linguistic_data_SCA.csv"))

# Note: File names above are example placeholders

```

# Preprocessing 1
```{r}
# Filter demographic dataset to specific variables
taskV_demographic_variables <- c("UserID_v2", "T2_PHQ9_Total", "Age", "Gender", "Education", "Diagnosis_Onset", "TaskV_1_Acceptability1", "TaskV_1_Acceptability2", "TaskV_1_Acceptability3")
taskV_demographic_data <- demographic_data[, taskV_demographic_variables]

# Order SCA dataset in ascending order of participant ID number
taskV_SCA$filename <- basename(taskV_TAASSC$filename)
taskV_SCA$filename <- str_remove(taskV_SCA$filename,".txt")
taskV_SCA$filename <- str_remove(taskV_SCA$filename,"TaskV.Participant")
taskV_SCA <- taskV_SCA[order(as.numeric(taskV_SCA$filename), decreasing = FALSE), ]
taskV_SCA$filename <- paste("Participant.", taskV_SCA$filename, sep = "")

# Order TAASSC dataset in ascending order of participant ID number
taskV_TAASSC$filename <- str_remove(taskV_TAASSC$filename,".txt")
taskV_TAASSC$filename <- str_remove(taskV_TAASSC$filename,"TaskV.Participant")
taskV_TAASSC <- taskV_TAASSC[order(as.numeric(taskV_TAASSC$filename), decreasing = FALSE), ]
taskV_TAASSC$filename <- paste("Participant.", taskV_TAASSC$filename, sep = "")

# Remove predictor variables with near-zero variance from TAASSC dataset
near_zero_table <- nearZeroVar(taskV_TAASSC, saveMetrics = TRUE)
near_zero_TAASSC <- nearZeroVar(taskV_TAASSC) 
taskV_TAASSC <- taskV_TAASSC[,-near_zero_TAASSC]

# Combine demographic dataset with TAASCC and SCA datasets (without duplicate participant ID number and word-count columns)
taskV_total <- cbind(taskV_demographic_data, taskV_TAASSC, taskV_SCA[,3:16])

# Identify and remove participants with invalid writing samples (i.e., word-count of zero)
invalid <- filter(taskV_total, nwords == 0)
taskV_filtered <- filter(taskV_total, nwords != 0)

# Remove second ID column
taskV_filtered <- taskV_filtered[,-which(colnames(taskV_filtered) == "filename")]

# Define gender and education as categorical variables in final dataset
taskV_filtered$Gender <- as.factor(taskV_filtered$Gender)
taskV_filtered$Education <- as.factor(taskV_filtered$Education)

# Final dataset
taskV_final <- taskV_filtered
taskV_final

```

# Descriptive Statistics of Writing Samples
```{r}
# Average number of words across writing samples
mean(taskV_final$nwords)

# SD number of words across writing samples
sd(taskV_final$nwords)

# Min number of words across writing samples
min(taskV_final$nwords)

# Max number of words across writing samples
max(taskV_final$nwords)

```

# Descriptive Statistics of Acceptability Scores of Final Participant Sample
```{r}
# Acceptability 1 = Difficulty
length(taskV_final$TaskV_1_Acceptability1)
mean(taskV_final$TaskV_1_Acceptability1)
sd(taskV_final$TaskV_1_Acceptability1)
min(taskV_final$TaskV_1_Acceptability1)
max(taskV_final$TaskV_1_Acceptability1)

# Acceptability 2 = Interest
length(taskV_final$TaskV_1_Acceptability2)
mean(taskV_final$TaskV_1_Acceptability2)
sd(taskV_final$TaskV_1_Acceptability2)
min(taskV_final$TaskV_1_Acceptability2)
max(taskV_final$TaskV_1_Acceptability2)

# Acceptability 3 = Willingness
length(taskV_final$TaskV_1_Acceptability3)
mean(taskV_final$TaskV_1_Acceptability3)
sd(taskV_final$TaskV_1_Acceptability3)
min(taskV_final$TaskV_1_Acceptability3)
max(taskV_final$TaskV_1_Acceptability3)

```

# Total PHQ-9 Score Descriptive Statistics
```{r}
# Descriptive Statistics
length(taskV_final$T2_PHQ9_Total)
mean(taskV_final$T2_PHQ9_Total)
sd(taskV_final$T2_PHQ9_Total)
min(taskV_final$T2_PHQ9_Total)
max(taskV_final$T2_PHQ9_Total)

# Total Number by Symptom Severity Category
nil_to_minimal <- c(0, 1, 2, 3, 4)
mild <- c(5, 6, 7, 8, 9)
moderate <- c(10, 11, 12, 13, 14)
moderately_severe <- c(15, 16, 17, 18, 19)
severe <- c(20, 21, 22, 23, 24, 25, 26, 27)

nrow(filter(taskV_final, T2_PHQ9_Total %in% nil_to_minimal)) # Nil to Minimal
nrow(filter(taskV_final, T2_PHQ9_Total %in% mild)) # Mild
nrow(filter(taskV_final, T2_PHQ9_Total %in% moderate)) # Moderate
nrow(filter(taskV_final, T2_PHQ9_Total %in% moderately_severe)) # Moderately Severe
nrow(filter(taskV_final, T2_PHQ9_Total %in% severe)) # Severe

# Total PHQ-9 Score >= 10 (Probable Depression)
nrow(filter(taskV_final, T2_PHQ9_Total >= 10))

```

# Preprocessing 2
Identify and remove highly-correlated predictor variables
```{r}
# Isolate dataset columns with predictor variables
taskV_variables <- taskV_final[,which(colnames(taskV_final)=="nwords"):dim(taskV_final)[2]] 

# Create correlation matrix of predictor variables
cor_matrix <- cor(taskV_variables, use = "complete.obs")

# Identify highly correlated variables
highly_correlated <- findCorrelation(cor_matrix, cutoff = 0.75)

# Add number of columns to vector of column names to align with length of original filtered dataset
highly_correlated <- highly_correlated + length(taskV_demographic_variables)

# Remove highly correlated variables from original filtered dataset
taskV_final <- taskV_final[,-highly_correlated]

# Final dataset
taskV_final

```

# Preprocessing 3
Correlations between linguistic variables and total PHQ-9 scores
With FDR correction

**NOTE: If applying edits that change dimensions of dataset, column reference numbers below need to be updated**

```{r}
# With FDR correction
taskV_final_df <- as.data.frame(taskV_final)
taskV_pvalues <- vector()

j = 1
for(i in 10:107){
  taskV_pvalues[j] <- cor.test(taskV_final_df$T2_PHQ9_Total, taskV_final_df[,i])$p.value
  j <- j+1
}

# specify 10:107 so only runs over linguistic variables 

taskV_pvalues <- p.adjust(taskV_pvalues, method = "fdr")
taskV_variables_refined <- colnames(taskV_final[,10:107])[which(taskV_pvalues < .05)]
taskV_final <- taskV_final[, c(taskV_demographic_variables,taskV_variables_refined)]
taskV_final

```

## Significant Bivariate Correlations From All Tasks
```{r}

taskV_cor1 <- cor.test(taskV_final_df$T2_PHQ9_Total, taskV_final_df$nn_pobj_deps_NN_struct)
taskV_cor2 <- cor.test(taskV_final_df$T2_PHQ9_Total, taskV_final_df$fic_lemma_ttr) 
taskV_cor3 <- cor.test(taskV_final_df$T2_PHQ9_Total, taskV_final_df$all_construction_ttr) 
taskV_cor4 <- cor.test(taskV_final_df$T2_PHQ9_Total, taskV_final_df$all_lemma_construction_attested) 
#taskV_cor5 <- cor.test(taskV_final_df$T2_PHQ9_Total, taskV_final_df$news_av_lemma_construction_freq_type) 
#taskV_cor6 <- cor.test(taskV_final_df$T2_PHQ9_Total, taskV_final_df$news_av_lemma_construction_freq_log_stdev) 

# 2 of the variables had been removed during preprocessing for TaskV

```

# Create Results Dataframe
```{r}
# create empty 6 x 3 matrix; convert matrix to dataframe; rename column names
taskV_results <- matrix(NA, nrow = 6, ncol = 3)
taskV_results <- data.frame(taskV_results) 
colnames(taskV_results) <- c("variable", "r", "p_value_adjusted")       

# fill dataframe with values from correlation results

# noun phrase complexity
taskV_results[1,1] <- "nn_pobj_deps_NN_struct"                      # row1 col1 = variable name
taskV_results[1,2] <- taskV_cor1$estimate                           # row1 col2 = pearson's r from cor1
taskV_results[1,3] <- p.adjust(taskV_cor1$p.value, method = "fdr")  # row1 col3 = FDR adjusted p-value from cor1

taskV_results[2,1] <- "fic_lemma_ttr"    
taskV_results[2,2] <- taskV_cor2$estimate         
taskV_results[2,3] <- p.adjust(taskV_cor2$p.value, method = "fdr")          

taskV_results[3,1] <- "all_construction_ttr"    
taskV_results[3,2] <- taskV_cor3$estimate         
taskV_results[3,3] <- p.adjust(taskV_cor3$p.value, method = "fdr")          

taskV_results[4,1] <- "all_lemma_construction_attested"    
taskV_results[4,2] <- taskV_cor4$estimate         
taskV_results[4,3] <- p.adjust(taskV_cor4$p.value, method = "fdr")          

taskV_results[5,1] <- "news_av_lemma_construction_freq_type"    
taskV_results[5,2] <- "NA"         
taskV_results[5,3] <- "NA"          

taskV_results[6,1] <- "news_av_lemma_construction_freq_log_stdev"    
taskV_results[6,2] <- "NA"         
taskV_results[6,3] <- "NA"

taskV_results

# NA = variables removed during preprocessing for TaskV but were significant in other tasks

```

# Scatterplots of Significant Correlations (with regression line)
Noun Phrase Complexity: nn_pobj_deps_NN_struct
```{r}

taskV_1 <- taskV_final_df %>%
  ggplot(mapping = aes(x = nn_pobj_deps_NN_struct, y = T2_PHQ9_Total)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = y ~ x,
              col = "blue") +
  theme_classic() +
  labs(title = "Task V: Personal Biography",
       subtitle = "Scatterplot between PHQ-9 Total and nn_pobj_deps_NN_struct",
       x = "nn_pobj_deps_NN_struct (Noun Phrase Complexity)",
       y = "PHQ-9 Score (Total) at Timepoint 2")

taskV_1

```

Syntactic Sophistication: fic_lemma_ttr
```{r}

taskV_2 <- taskV_final_df %>%
  ggplot(mapping = aes(x = fic_lemma_ttr, y = T2_PHQ9_Total)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = y ~ x,
              col = "blue") +
  theme_classic() +
  labs(title = "Task V: Personal Biography",
       subtitle = "Scatterplot between PHQ-9 Total and fic_lemma_ttr",
       x = "fic_lemma_ttr (Syntactic Sophistication)",
       y = "PHQ-9 Score (Total) at Timepoint 2")

taskV_2
  
```

Syntactic Sophistication: all_construction_ttr
```{r}

taskV_3 <- taskV_final_df %>%
  ggplot(mapping = aes(x = all_construction_ttr, y = T2_PHQ9_Total)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = y ~ x,
              col = "blue") +
  theme_classic() +
  labs(title = "Task V: Personal Biography",
       subtitle = "Scatterplot between PHQ-9 Total and all_construction_ttr",
       x = "all_construction_ttr (Syntactic Sophistication)",
       y = "PHQ-9 Score (Total) at Timepoint 2")

taskV_3

```

Syntactic Sophistication: all_lemma_construction_attested
```{r}

taskV_4 <- taskV_final_df %>%
  ggplot(mapping = aes(x = all_lemma_construction_attested, y = T2_PHQ9_Total)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = y ~ x,
              col = "blue") +
  theme_classic() +
  labs(title = "Task V: Personal Biography",
       subtitle = "Scatterplot between PHQ-9 Total and all_lemma_construction_attested",
       x = "all_lemma_construction_attested (Syntactic Sophistication)",
       y = "PHQ-9 Score (Total) at Timepoint 2")

taskV_4

```
